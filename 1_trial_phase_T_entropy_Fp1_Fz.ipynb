{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the main path and file paths\n",
    "main_path = r'D:\\Fateme A\\23_Brain Electrophysiological Recording during Olfactory Stimulation in Mild Cognitive Impairment and Alzheimer Disease Patients An EEG Dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial counts per class: {'AD': 1352, 'normal': 1677, 'MCI': 848}\n",
      "trial number to balance classes: 848\n",
      "3 * 848 =  2544\n",
      "we used random selection of trials to balance classes\n",
      "Final balanced dataset:\n",
      "Data shape: (2544, 4, 600)\n",
      "Labels shape: (2544,)\n",
      "Labels: (array(['AD', 'MCI', 'normal'], dtype='<U6'), array([848, 848, 848]))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import random\n",
    "\n",
    "# Define file names\n",
    "file_paths = {\n",
    "    \"AD\": os.path.join(main_path, \"AD.mat\"),\n",
    "    \"normal\": os.path.join(main_path, \"normal.mat\"),\n",
    "    \"MCI\": os.path.join(main_path, \"MCI.mat\")\n",
    "}\n",
    "\n",
    "# Prepare storage per class\n",
    "class_data = {\n",
    "    \"AD\": [],\n",
    "    \"normal\": [],\n",
    "    \"MCI\": []\n",
    "}\n",
    "\n",
    "# Load and organize all trials by class\n",
    "for label, file_path in file_paths.items():\n",
    "    mat_data = scipy.io.loadmat(file_path)\n",
    "    eeg_data = mat_data[label]  # Assuming variable name matches label\n",
    "\n",
    "    for patient_id in range(eeg_data.shape[1]):  # shape: (1, N_patients)\n",
    "        patient_data = eeg_data[0][patient_id]\n",
    "        trials = patient_data[0]  # shape: channels x samples x trials\n",
    "\n",
    "        # Split into individual trials and add to class list\n",
    "        for i in range(trials.shape[2]):\n",
    "            class_data[label].append(trials[:, :, i])  # One trial\n",
    "\n",
    "# Calculate total trial counts per class\n",
    "trial_counts = {label: len(trials) for label, trials in class_data.items()}\n",
    "print(\"Trial counts per class:\", trial_counts)\n",
    "\n",
    "# Find the minimum number of trials across the 3 classes\n",
    "min_trial_count = min(trial_counts.values())\n",
    "print(\"trial number to balance classes:\", min_trial_count)\n",
    "\n",
    "# Randomly select min_trial_count trials from each class\n",
    "balanced_data = []\n",
    "balanced_labels = []\n",
    "\n",
    "for label in class_data:\n",
    "    selected_trials = random.sample(class_data[label], min_trial_count)\n",
    "    balanced_data.extend(selected_trials)\n",
    "    balanced_labels.extend([label] * min_trial_count)\n",
    "\n",
    "# Convert to arrays\n",
    "data_array = np.stack(balanced_data)  # shape: total_trials x channels x samples\n",
    "labels_array = np.array(balanced_labels)\n",
    "\n",
    "# Final output info\n",
    "print(\"3 * 848 = \", data_array.shape[0])\n",
    "print('we used random selection of trials to balance classes')\n",
    "\n",
    "print(\"Final balanced dataset:\")\n",
    "print(\"Data shape:\", data_array.shape)\n",
    "print(\"Labels shape:\", labels_array.shape)\n",
    "print(\"Labels:\", np.unique(labels_array, return_counts=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Entropy Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import hilbert\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "def compute_phase(signal):\n",
    "    \"\"\"Compute instantaneous phase via Hilbert transform.\"\"\"\n",
    "    analytic_signal = hilbert(signal)\n",
    "    phase = np.angle(analytic_signal)\n",
    "    return phase\n",
    "\n",
    "def bin_phases(phases, n_bins):\n",
    "    \"\"\"Discretize continuous phases into n_bins states uniformly.\"\"\"\n",
    "    # phases in [-π, π]\n",
    "    est = KBinsDiscretizer(n_bins=n_bins, encode='ordinal', strategy='uniform', subsample=None)\n",
    "    return est.fit_transform(phases.reshape(-1, 1)).astype(int).flatten()\n",
    "\n",
    "def estimate_joint_probabilities(data, n_bins):\n",
    "    \"\"\"Estimate joint probability distribution from 2D array of binned variables.\"\"\"\n",
    "    # Each row = variable, columns = samples\n",
    "    # data.shape = (variables, N)\n",
    "    variables, N = data.shape\n",
    "    joint_counts = np.zeros([n_bins]*variables, dtype=np.float64)\n",
    "    for i in range(N):\n",
    "        idx = tuple(data[:, i])\n",
    "        joint_counts[idx] += 1\n",
    "    joint_probs = joint_counts / joint_counts.sum()\n",
    "    return joint_probs\n",
    "\n",
    "def phase_transfer_entropy(signal_a, signal_b, delta=1, n_bins=8):\n",
    "    \"\"\"\n",
    "    Computes Phase Transfer Entropy from signal_b (driver) to signal_a (target)\n",
    "    using the formula from the image.\n",
    "    \"\"\"\n",
    "    # Step 1: Compute instantaneous phases\n",
    "    phase_a = compute_phase(signal_a)\n",
    "    phase_b = compute_phase(signal_b)\n",
    "\n",
    "    # Step 2: Embed\n",
    "    # A_delta = future of A\n",
    "    A_delta = phase_a[delta:]\n",
    "    A_past = phase_a[:-delta]\n",
    "    B_past = phase_b[:-delta]\n",
    "\n",
    "    N_effective = len(A_delta)\n",
    "\n",
    "    # Step 3: Bin phases\n",
    "    A_delta_binned = bin_phases(A_delta, n_bins)\n",
    "    A_past_binned = bin_phases(A_past, n_bins)\n",
    "    B_past_binned = bin_phases(B_past, n_bins)\n",
    "\n",
    "    # Step 4: Build joint data\n",
    "    data_A_delta_A_B = np.vstack([A_delta_binned, A_past_binned, B_past_binned])\n",
    "    data_A_delta_A = np.vstack([A_delta_binned, A_past_binned])\n",
    "\n",
    "    # Step 5: Estimate probabilities\n",
    "    p_A_delta_A_B = estimate_joint_probabilities(data_A_delta_A_B, n_bins)\n",
    "    p_A_delta_A = estimate_joint_probabilities(data_A_delta_A, n_bins)\n",
    "\n",
    "    # Step 6: Compute sum\n",
    "    PTE = 0.0\n",
    "    for i in range(n_bins):\n",
    "        for j in range(n_bins):\n",
    "            for k in range(n_bins):\n",
    "                p_joint = p_A_delta_A_B[i, j, k]\n",
    "                if p_joint == 0:\n",
    "                    continue\n",
    "\n",
    "                p_cond_AB = p_joint / (p_A_delta_A_B[:, j, k].sum() + 1e-12)\n",
    "                p_cond_A = p_A_delta_A[i, j] / (p_A_delta_A[:, j].sum() + 1e-12)\n",
    "\n",
    "                if p_cond_AB > 0 and p_cond_A > 0:\n",
    "                    PTE += p_joint * np.log2(p_cond_AB / p_cond_A)\n",
    "\n",
    "    return PTE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transfer Entropy Band Analysis Functions Ready!\n",
      "\n",
      "Available Functions:\n",
      "==================================================\n",
      "1. evaluate_all_band_combinations_transfer_entropy(data_array, labels_array)\n",
      "   - Analyzes transfer entropy between ALL frequency band combinations\n",
      "   - Includes comprehensive visualizations and summary tables\n",
      "\n",
      "2. evaluate_features(data_array, labels_array)\n",
      "   - Legacy full bandwidth analysis\n",
      "   - Uses transfer entropy between channels or filtered versions\n",
      "\n",
      "3. evaluate_band_to_band_transfer_entropy(data_array, labels_array, 'alpha', (8, 14), 'beta', (14, 30))\n",
      "   - Analyzes specific band-to-band transfer entropy\n",
      "\n",
      "Required data format:\n",
      "- data_array: shape (trials, channels, samples)\n",
      "- labels_array: shape (trials,)\n",
      "\n",
      "Note: The transfer_entropy(x, y) function is included as a placeholder.\n",
      "      Replace it with your actual transfer entropy implementation!\n",
      "\n",
      "Example usage:\n",
      "results = evaluate_all_band_combinations_transfer_entropy(data_array, labels_array)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.signal import butter, filtfilt\n",
    "\n",
    "# === Classifiers ===\n",
    "classifiers = {\n",
    "    'SVM': SVC(kernel='rbf', random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, solver='lbfgs', C=1.0, random_state=42),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# Define frequency bands\n",
    "bands = {\n",
    "    \"delta\": (0.1, 4),\n",
    "    \"theta\": (4, 8),\n",
    "    \"alpha\": (8, 14),\n",
    "    \"beta\": (14, 30),\n",
    "    \"gamma\": (30, 40)\n",
    "}\n",
    "\n",
    "def bandpass_filter(signal, lowcut=0.1, highcut=40.0, fs=200.0, order=3):\n",
    "    \"\"\"Apply a Butterworth bandpass filter to a signal.\"\"\"\n",
    "    nyquist = 0.5 * fs\n",
    "    low = lowcut / nyquist\n",
    "    high = highcut / nyquist\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return filtfilt(b, a, signal)\n",
    "\n",
    "# --- Transfer entropy feature extraction for specific bands ---\n",
    "def extract_transfer_entropy_features_between_bands(trial, band_range_1, band_range_2):\n",
    "    \"\"\"\n",
    "    Extract phase transfer entropy features between two frequency bands from the same channel.\n",
    "    trial shape: (channels, samples)\n",
    "    band_range_1: tuple (low_freq, high_freq) for first band\n",
    "    band_range_2: tuple (low_freq, high_freq) for second band\n",
    "    \"\"\"\n",
    "    low_freq_1, high_freq_1 = band_range_1\n",
    "    low_freq_2, high_freq_2 = band_range_2\n",
    "    \n",
    "    # Get first channel (can be modified to use different channels)\n",
    "    ch1 = trial[0, :]\n",
    "    \n",
    "    # Filter the same channel for two different frequency bands\n",
    "    band_1_signal = bandpass_filter(ch1, low_freq_1, high_freq_1, fs=200)\n",
    "    band_2_signal = bandpass_filter(ch1, low_freq_2, high_freq_2, fs=200)\n",
    "    \n",
    "    # Calculate transfer entropy between the filtered band signals\n",
    "    te_feature = phase_transfer_entropy(band_1_signal, band_2_signal)\n",
    "    \n",
    "    return [te_feature]\n",
    "\n",
    "def process_data_band_to_band_transfer_entropy(data_array, band_range_1, band_range_2):\n",
    "    \"\"\"\n",
    "    Process data array and extract phase transfer entropy features between two frequency bands.\n",
    "    data_array: shape (trials, channels, samples)\n",
    "    band_range_1: tuple (low_freq, high_freq) for source band\n",
    "    band_range_2: tuple (low_freq, high_freq) for target band\n",
    "    \"\"\"\n",
    "    feature_list = []\n",
    "    for trial_data in data_array:\n",
    "        trial_data = np.array(trial_data, dtype=np.float64)\n",
    "        \n",
    "        # Extract transfer entropy features between the two bands\n",
    "        trial_features = extract_transfer_entropy_features_between_bands(trial_data, band_range_1, band_range_2)\n",
    "        feature_list.append(trial_features)\n",
    "    \n",
    "    return np.array(feature_list)\n",
    "\n",
    "def evaluate_band_to_band_transfer_entropy(data_array, labels_array, band_name_1, band_range_1, band_name_2, band_range_2):\n",
    "    \"\"\"\n",
    "    Evaluate classifiers using phase transfer entropy features between two frequency bands.\n",
    "    \"\"\"\n",
    "    print(f\"\\n=== Evaluating Transfer Entropy: {band_name_1.upper()} → {band_name_2.upper()} ===\")\n",
    "\n",
    "    # Extract transfer entropy features between the two bands\n",
    "    X = process_data_band_to_band_transfer_entropy(data_array, band_range_1, band_range_2)\n",
    "\n",
    "    # Encode labels\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(labels_array)\n",
    "\n",
    "    # Prepare cross-validation\n",
    "    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for name, clf in classifiers.items():\n",
    "        pipeline = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('classifier', clf)\n",
    "        ])\n",
    "\n",
    "        scores = cross_val_score(pipeline, X, y_encoded, cv=skf, scoring='accuracy')\n",
    "\n",
    "        results[name] = {\n",
    "            'Mean Accuracy': np.mean(scores),\n",
    "            'Std Accuracy': np.std(scores),\n",
    "            'All Scores': scores\n",
    "        }\n",
    "\n",
    "        print(f\"{name}: {np.mean(scores):.3f} ± {np.std(scores):.3f}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "def evaluate_all_band_combinations_transfer_entropy(data_array, labels_array):\n",
    "    \"\"\"\n",
    "    Evaluate phase transfer entropy features for all frequency band combinations.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"EVALUATING Phase TRANSFER ENTROPY BETWEEN ALL FREQUENCY BAND COMBINATIONS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    all_results = {}\n",
    "    \n",
    "    # Evaluate each band combination (including self-connections and bidirectional)\n",
    "    for band_name_1, band_range_1 in bands.items():\n",
    "        for band_name_2, band_range_2 in bands.items():\n",
    "            if band_name_1 == band_name_2:\n",
    "                # Skip self-connections (e.g., alpha to alpha)\n",
    "                continue\n",
    "            combination_key = f\"{band_name_1}_to_{band_name_2}\"\n",
    "            band_results = evaluate_band_to_band_transfer_entropy(\n",
    "                data_array, labels_array, band_name_1, band_range_1, band_name_2, band_range_2\n",
    "            )\n",
    "            all_results[combination_key] = band_results\n",
    "    \n",
    "    # Create comprehensive visualization\n",
    "    create_comprehensive_transfer_entropy_plots(all_results)\n",
    "    \n",
    "    # Print summary table\n",
    "    create_comprehensive_summary_table(all_results)\n",
    "    \n",
    "    return all_results\n",
    "\n",
    "def create_comprehensive_transfer_entropy_plots(all_results):\n",
    "    \"\"\"\n",
    "    Create comprehensive plots comparing phase transfer entropy performance across band combinations and classifiers.\n",
    "    \"\"\"\n",
    "    # Prepare data for plotting\n",
    "    plot_data = []\n",
    "    for combination_name, combination_results in all_results.items():\n",
    "        source_band, target_band = combination_name.split('_to_')\n",
    "        for classifier_name, metrics in combination_results.items():\n",
    "            plot_data.append({\n",
    "                'Source Band': source_band.title(),\n",
    "                'Target Band': target_band.title(),\n",
    "                'Combination': f\"{source_band.title()} → {target_band.title()}\",\n",
    "                'Classifier': classifier_name,\n",
    "                'Mean Accuracy': metrics['Mean Accuracy'],\n",
    "                'Std Accuracy': metrics['Std Accuracy']\n",
    "            })\n",
    "    \n",
    "    df = pd.DataFrame(plot_data)\n",
    "    \n",
    "    # Create comprehensive figure with multiple subplots\n",
    "    fig = plt.figure(figsize=(24, 16))\n",
    "    \n",
    "    # Main title\n",
    "    fig.suptitle('Phase Transfer Entropy Classification Performance: Band-to-Band Analysis', \n",
    "                 fontsize=20, fontweight='bold', y=0.98)\n",
    "    \n",
    "    # Create grid layout\n",
    "    gs = fig.add_gridspec(3, 4, hspace=0.3, wspace=0.3)\n",
    "    \n",
    "    # Plot 1: Overall accuracy heatmap by combination\n",
    "    ax1 = fig.add_subplot(gs[0, :2])\n",
    "    pivot_accuracy = df.groupby(['Source Band', 'Target Band'])['Mean Accuracy'].mean().unstack()\n",
    "    sns.heatmap(pivot_accuracy, annot=True, fmt='.3f', cmap='viridis', ax=ax1, cbar_kws={'label': 'Mean Accuracy'})\n",
    "    ax1.set_title('Mean Accuracy Heatmap: Source → Target Band Combinations', fontweight='bold')\n",
    "    ax1.set_xlabel('Target Band')\n",
    "    ax1.set_ylabel('Source Band')\n",
    "    \n",
    "    # Plot 2: Best classifier per combination\n",
    "    ax2 = fig.add_subplot(gs[0, 2:])\n",
    "    best_per_combination = df.loc[df.groupby('Combination')['Mean Accuracy'].idxmax()]\n",
    "    best_per_combination_sorted = best_per_combination.nlargest(15, 'Mean Accuracy')\n",
    "    \n",
    "    sns.barplot(data=best_per_combination_sorted, y='Combination', x='Mean Accuracy', \n",
    "                hue='Classifier', ax=ax2, palette='Set2')\n",
    "    ax2.set_title('Top 15 Band Combinations (Best Classifier Each)', fontweight='bold')\n",
    "    ax2.set_xlabel('Mean Accuracy')\n",
    "    ax2.set_ylabel('Band Combination')\n",
    "    ax2.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    # Plot 3: Classifier performance comparison\n",
    "    ax3 = fig.add_subplot(gs[1, :2])\n",
    "    classifier_performance = df.groupby('Classifier')['Mean Accuracy'].agg(['mean', 'std']).reset_index()\n",
    "    classifier_performance = classifier_performance.sort_values('mean', ascending=True)\n",
    "    \n",
    "    bars = ax3.barh(classifier_performance['Classifier'], classifier_performance['mean'], \n",
    "                    xerr=classifier_performance['std'], capsize=5, color='skyblue', alpha=0.7)\n",
    "    ax3.set_title('Average Classifier Performance Across All Band Combinations', fontweight='bold')\n",
    "    ax3.set_xlabel('Mean Accuracy')\n",
    "    ax3.set_ylabel('Classifier')\n",
    "    ax3.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for i, (bar, mean_val) in enumerate(zip(bars, classifier_performance['mean'])):\n",
    "        ax3.text(bar.get_width() + 0.01, bar.get_y() + bar.get_height()/2, \n",
    "                f'{mean_val:.3f}', ha='left', va='center', fontweight='bold')\n",
    "    \n",
    "    # Plot 4: Source band analysis\n",
    "    ax4 = fig.add_subplot(gs[1, 2:])\n",
    "    source_performance = df.groupby('Source Band')['Mean Accuracy'].agg(['mean', 'std']).reset_index()\n",
    "    source_performance = source_performance.sort_values('mean', ascending=False)\n",
    "    \n",
    "    sns.barplot(data=source_performance, x='Source Band', y='mean', ax=ax4, palette='viridis')\n",
    "    ax4.errorbar(range(len(source_performance)), source_performance['mean'], \n",
    "                yerr=source_performance['std'], fmt='none', color='black', capsize=5)\n",
    "    ax4.set_title('Average Performance by Source Band', fontweight='bold')\n",
    "    ax4.set_xlabel('Source Band')\n",
    "    ax4.set_ylabel('Mean Accuracy')\n",
    "    ax4.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Plot 5: Distribution of accuracies\n",
    "    ax5 = fig.add_subplot(gs[2, :2])\n",
    "    sns.violinplot(data=df, x='Classifier', y='Mean Accuracy', ax=ax5, palette='Set3')\n",
    "    ax5.set_title('Distribution of Accuracies by Classifier', fontweight='bold')\n",
    "    ax5.set_xlabel('Classifier')\n",
    "    ax5.set_ylabel('Mean Accuracy')\n",
    "    ax5.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Plot 6: Top performing combinations detailed view\n",
    "    ax6 = fig.add_subplot(gs[2, 2:])\n",
    "    top_combinations = df.nlargest(20, 'Mean Accuracy')\n",
    "    \n",
    "    # Create a scatter plot with different colors for each classifier\n",
    "    for classifier in top_combinations['Classifier'].unique():\n",
    "        classifier_data = top_combinations[top_combinations['Classifier'] == classifier]\n",
    "        ax6.scatter(classifier_data['Mean Accuracy'], classifier_data['Combination'], \n",
    "                   label=classifier, alpha=0.7, s=60)\n",
    "    \n",
    "    ax6.set_title('Top 20 Performances: Combination vs Accuracy', fontweight='bold')\n",
    "    ax6.set_xlabel('Mean Accuracy')\n",
    "    ax6.set_ylabel('Band Combination')\n",
    "    ax6.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    ax6.grid(alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def create_comprehensive_summary_table(all_results):\n",
    "    \"\"\"\n",
    "    Create and print a comprehensive summary table for phase transfer entropy results.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*120)\n",
    "    print(\"PHASE TRANSFER ENTROPY BETWEEN FREQUENCY BANDS - COMPREHENSIVE SUMMARY\")\n",
    "    print(\"=\"*120)\n",
    "    \n",
    "    # Create summary dataframe\n",
    "    summary_data = []\n",
    "    for combination_name, combination_results in all_results.items():\n",
    "        source_band, target_band = combination_name.split('_to_')\n",
    "        for classifier_name, metrics in combination_results.items():\n",
    "            summary_data.append({\n",
    "                'Source Band': source_band.title(),\n",
    "                'Target Band': target_band.title(),\n",
    "                'Combination': f\"{source_band.title()} → {target_band.title()}\",\n",
    "                'Classifier': classifier_name,\n",
    "                'Mean Accuracy': metrics['Mean Accuracy'],\n",
    "                'Std Accuracy': metrics['Std Accuracy'],\n",
    "                'Performance': f\"{metrics['Mean Accuracy']:.3f} ± {metrics['Std Accuracy']:.3f}\"\n",
    "            })\n",
    "    \n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    \n",
    "    # Print top 20 performances\n",
    "    print(\"TOP 20 PERFORMANCES:\")\n",
    "    print(\"-\" * 120)\n",
    "    top_20 = summary_df.nlargest(20, 'Mean Accuracy')[['Combination', 'Classifier', 'Performance']]\n",
    "    print(top_20.to_string(index=False))\n",
    "    \n",
    "    # Print best performance per band combination\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"BEST CLASSIFIER PER BAND COMBINATION:\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    best_per_combination = summary_df.loc[summary_df.groupby('Combination')['Mean Accuracy'].idxmax()]\n",
    "    best_per_combination_sorted = best_per_combination.sort_values('Mean Accuracy', ascending=False)\n",
    "    \n",
    "    for _, row in best_per_combination_sorted.head(15).iterrows():\n",
    "        print(f\"{row['Combination']:20s}: {row['Classifier']:18s} - {row['Performance']}\")\n",
    "    \n",
    "    # Print best performance per classifier\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"BEST BAND COMBINATION PER CLASSIFIER:\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    best_per_classifier = summary_df.loc[summary_df.groupby('Classifier')['Mean Accuracy'].idxmax()]\n",
    "    best_per_classifier_sorted = best_per_classifier.sort_values('Mean Accuracy', ascending=False)\n",
    "    \n",
    "    for _, row in best_per_classifier_sorted.iterrows():\n",
    "        print(f\"{row['Classifier']:18s}: {row['Combination']:20s} - {row['Performance']}\")\n",
    "    \n",
    "    # Print overall statistics\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"OVERALL STATISTICS:\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    overall_best = summary_df.loc[summary_df['Mean Accuracy'].idxmax()]\n",
    "    print(f\"Best Overall Performance: {overall_best['Combination']} with {overall_best['Classifier']} - {overall_best['Performance']}\")\n",
    "    print(f\"Average Accuracy Across All Combinations: {summary_df['Mean Accuracy'].mean():.3f} ± {summary_df['Mean Accuracy'].std():.3f}\")\n",
    "    print(f\"Median Accuracy: {summary_df['Mean Accuracy'].median():.3f}\")\n",
    "    print(f\"Range: {summary_df['Mean Accuracy'].min():.3f} - {summary_df['Mean Accuracy'].max():.3f}\")\n",
    "\n",
    "def process_data(data_array, feature_extractor):\n",
    "    \"\"\"\n",
    "    Legacy function - process data using full bandwidth.\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    for trial in data_array:\n",
    "        trial = np.array(trial, dtype=np.float64)\n",
    "        # Apply bandpass filter to entire trial\n",
    "        if trial.ndim == 2:\n",
    "            filtered_signal = np.array([bandpass_filter(trial[i], fs=200) for i in range(trial.shape[0])])\n",
    "        else:\n",
    "            filtered_signal = bandpass_filter(trial, fs=200)\n",
    "        feat = feature_extractor(filtered_signal)\n",
    "        features.append(feat)\n",
    "    return np.array(features)\n",
    "\n",
    "def create_legacy_performance_plot(results):\n",
    "    \"\"\"\n",
    "    Create an improved plot for legacy full-bandwidth results.\n",
    "    \"\"\"\n",
    "    accuracy_df = pd.DataFrame({\n",
    "        'Classifier': list(results.keys()),\n",
    "        'Mean Accuracy': [results[m]['Mean Accuracy'] for m in results],\n",
    "        'Std Accuracy': [results[m]['Std Accuracy'] for m in results]\n",
    "    }).sort_values(by='Mean Accuracy', ascending=False)\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Create bar plot with error bars\n",
    "    bars = plt.bar(accuracy_df['Classifier'], accuracy_df['Mean Accuracy'], \n",
    "                   yerr=accuracy_df['Std Accuracy'], capsize=5, \n",
    "                   color='steelblue', alpha=0.7, edgecolor='navy')\n",
    "\n",
    "    # Add value labels on bars\n",
    "    for bar, (_, row) in zip(bars, accuracy_df.iterrows()):\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height + row['Std Accuracy'] + 0.01,\n",
    "                f'{row[\"Mean Accuracy\"]:.3f}±{row[\"Std Accuracy\"]:.3f}', \n",
    "                ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "    plt.title(\"10-Fold Cross-Validated Accuracy using Phase Transfer Entropy Features\\n(Full Bandwidth Analysis)\", \n",
    "              fontsize=14, fontweight='bold')\n",
    "    plt.ylabel(\"Accuracy\", fontsize=12)\n",
    "    plt.xlabel(\"Classifier\", fontsize=12)\n",
    "    plt.ylim(0, min(1.0, accuracy_df['Mean Accuracy'].max() + accuracy_df['Std Accuracy'].max() + 0.1))\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# ============================================================================\n",
    "# USAGE EXAMPLES:\n",
    "# ============================================================================\n",
    "\n",
    "print(\"Transfer Entropy Band Analysis Functions Ready!\")\n",
    "print(\"\\nAvailable Functions:\")\n",
    "print(\"=\"*50)\n",
    "print(\"1. evaluate_all_band_combinations_transfer_entropy(data_array, labels_array)\")\n",
    "print(\"   - Analyzes transfer entropy between ALL frequency band combinations\")\n",
    "print(\"   - Includes comprehensive visualizations and summary tables\")\n",
    "print(\"\")\n",
    "print(\"2. evaluate_features(data_array, labels_array)\")\n",
    "print(\"   - Legacy full bandwidth analysis\")\n",
    "print(\"   - Uses transfer entropy between channels or filtered versions\")\n",
    "print(\"\")\n",
    "print(\"3. evaluate_band_to_band_transfer_entropy(data_array, labels_array, 'alpha', (8, 14), 'beta', (14, 30))\")\n",
    "print(\"   - Analyzes specific band-to-band transfer entropy\")\n",
    "print(\"\")\n",
    "print(\"Required data format:\")\n",
    "print(\"- data_array: shape (trials, channels, samples)\")\n",
    "print(\"- labels_array: shape (trials,)\")\n",
    "print(\"\")\n",
    "print(\"Note: The transfer_entropy(x, y) function is included as a placeholder.\")\n",
    "print(\"      Replace it with your actual transfer entropy implementation!\")\n",
    "print(\"\")\n",
    "print(\"Example usage:\")\n",
    "print(\"results = evaluate_all_band_combinations_transfer_entropy(data_array, labels_array)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "EVALUATING Phase TRANSFER ENTROPY BETWEEN ALL FREQUENCY BAND COMBINATIONS\n",
      "================================================================================\n",
      "\n",
      "=== Evaluating Transfer Entropy: DELTA → THETA ===\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mevaluate_all_band_combinations_transfer_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels_array\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[7], line 134\u001b[0m, in \u001b[0;36mevaluate_all_band_combinations_transfer_entropy\u001b[1;34m(data_array, labels_array)\u001b[0m\n\u001b[0;32m    132\u001b[0m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m    133\u001b[0m         combination_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mband_name_1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_to_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mband_name_2\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 134\u001b[0m         band_results \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_band_to_band_transfer_entropy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mband_name_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mband_range_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mband_name_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mband_range_2\u001b[49m\n\u001b[0;32m    136\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    137\u001b[0m         all_results[combination_key] \u001b[38;5;241m=\u001b[39m band_results\n\u001b[0;32m    139\u001b[0m \u001b[38;5;66;03m# Create comprehensive visualization\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[7], line 105\u001b[0m, in \u001b[0;36mevaluate_band_to_band_transfer_entropy\u001b[1;34m(data_array, labels_array, band_name_1, band_range_1, band_name_2, band_range_2)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, clf \u001b[38;5;129;01min\u001b[39;00m classifiers\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    100\u001b[0m     pipeline \u001b[38;5;241m=\u001b[39m Pipeline([\n\u001b[0;32m    101\u001b[0m         (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscaler\u001b[39m\u001b[38;5;124m'\u001b[39m, StandardScaler()),\n\u001b[0;32m    102\u001b[0m         (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassifier\u001b[39m\u001b[38;5;124m'\u001b[39m, clf)\n\u001b[0;32m    103\u001b[0m     ])\n\u001b[1;32m--> 105\u001b[0m     scores \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpipeline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_encoded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    107\u001b[0m     results[name] \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    108\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMean Accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mmean(scores),\n\u001b[0;32m    109\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStd Accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mstd(scores),\n\u001b[0;32m    110\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAll Scores\u001b[39m\u001b[38;5;124m'\u001b[39m: scores\n\u001b[0;32m    111\u001b[0m     }\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mmean(scores)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ± \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mstd(scores)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    214\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    215\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    216\u001b[0m         )\n\u001b[0;32m    217\u001b[0m     ):\n\u001b[1;32m--> 218\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    224\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    226\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    227\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    228\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:677\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    674\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    675\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[1;32m--> 677\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    680\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    681\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    682\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    683\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    684\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    685\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    686\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    687\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    688\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    689\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    690\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    214\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    215\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    216\u001b[0m         )\n\u001b[0;32m    217\u001b[0m     ):\n\u001b[1;32m--> 218\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    224\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    226\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    227\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    228\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:399\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    397\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    398\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 399\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    400\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    401\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    402\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    403\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    406\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    407\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    408\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    409\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscore_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    415\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    416\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\n\u001b[0;32m    417\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    419\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    421\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    422\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    423\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py:82\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     73\u001b[0m warning_filters \u001b[38;5;241m=\u001b[39m warnings\u001b[38;5;241m.\u001b[39mfilters\n\u001b[0;32m     74\u001b[0m iterable_with_config_and_warning_filters \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     75\u001b[0m     (\n\u001b[0;32m     76\u001b[0m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     81\u001b[0m )\n\u001b[1;32m---> 82\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py:147\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig), warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[0;32m    146\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mfilters \u001b[38;5;241m=\u001b[39m warning_filters\n\u001b[1;32m--> 147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:859\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    857\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    858\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 859\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    862\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    863\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1358\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1360\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1361\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1362\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1363\u001b[0m     )\n\u001b[0;32m   1364\u001b[0m ):\n\u001b[1;32m-> 1365\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\pipeline.py:663\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    657\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    658\u001b[0m         last_step_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_metadata_for_step(\n\u001b[0;32m    659\u001b[0m             step_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m    660\u001b[0m             step_params\u001b[38;5;241m=\u001b[39mrouted_params[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]],\n\u001b[0;32m    661\u001b[0m             all_params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[0;32m    662\u001b[0m         )\n\u001b[1;32m--> 663\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_final_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mlast_step_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    665\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1358\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1360\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1361\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1362\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1363\u001b[0m     )\n\u001b[0;32m   1364\u001b[0m ):\n\u001b[1;32m-> 1365\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\svm\\_base.py:258\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    255\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LibSVM]\u001b[39m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    257\u001b[0m seed \u001b[38;5;241m=\u001b[39m rnd\u001b[38;5;241m.\u001b[39mrandint(np\u001b[38;5;241m.\u001b[39miinfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mmax)\n\u001b[1;32m--> 258\u001b[0m \u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msolver_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;66;03m# see comment on the other call to np.iinfo in this file\u001b[39;00m\n\u001b[0;32m    261\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape_fit_ \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m (n_samples,)\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\svm\\_base.py:336\u001b[0m, in \u001b[0;36mBaseLibSVM._dense_fit\u001b[1;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[0;32m    322\u001b[0m libsvm\u001b[38;5;241m.\u001b[39mset_verbosity_wrap(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose)\n\u001b[0;32m    324\u001b[0m \u001b[38;5;66;03m# we don't pass **self.get_params() to allow subclasses to\u001b[39;00m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;66;03m# add other parameters to __init__\u001b[39;00m\n\u001b[0;32m    326\u001b[0m (\n\u001b[0;32m    327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupport_,\n\u001b[0;32m    328\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupport_vectors_,\n\u001b[0;32m    329\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_support,\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdual_coef_,\n\u001b[0;32m    331\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_,\n\u001b[0;32m    332\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_probA,\n\u001b[0;32m    333\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_probB,\n\u001b[0;32m    334\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_status_,\n\u001b[0;32m    335\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_iter,\n\u001b[1;32m--> 336\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[43mlibsvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    338\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    339\u001b[0m \u001b[43m    \u001b[49m\u001b[43msvm_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    340\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    341\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclass_weight_\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    342\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkernel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    343\u001b[0m \u001b[43m    \u001b[49m\u001b[43mC\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    345\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprobability\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprobability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdegree\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdegree\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshrinking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshrinking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcache_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcoef0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoef0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgamma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepsilon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_seed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    357\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_warn_from_fit_status()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "evaluate_all_band_combinations_transfer_entropy(data_array, labels_array)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
